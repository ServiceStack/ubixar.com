{
  "client_id": "03078ddb89e3454a9af5f850f6318f9c",
  "prompt": {
    "3": {
      "inputs": {
        "seed": 978813273223451,
        "steps": 20,
        "cfg": 6,
        "sampler_name": "uni_pc",
        "scheduler": "simple",
        "denoise": 1,
        "model": [
          "54",
          0
        ],
        "positive": [
          "50",
          0
        ],
        "negative": [
          "50",
          1
        ],
        "latent_image": [
          "50",
          2
        ]
      },
      "class_type": "KSampler",
      "_meta": {
        "title": "KSampler"
      }
    },
    "6": {
      "inputs": {
        "text": "a cute anime girl with massive fennec ears and a big fluffy tail wearing a maid outfit turning around",
        "clip": [
          "38",
          0
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Positive Prompt)"
      }
    },
    "7": {
      "inputs": {
        "text": "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走",
        "clip": [
          "38",
          0
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Negative Prompt)"
      }
    },
    "8": {
      "inputs": {
        "samples": [
          "3",
          0
        ],
        "vae": [
          "39",
          0
        ]
      },
      "class_type": "VAEDecode",
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "28": {
      "inputs": {
        "filename_prefix": "ComfyUI",
        "fps": 16,
        "lossless": false,
        "quality": 90,
        "method": "default",
        "images": [
          "8",
          0
        ]
      },
      "class_type": "SaveAnimatedWEBP",
      "_meta": {
        "title": "SaveAnimatedWEBP"
      }
    },
    "37": {
      "inputs": {
        "unet_name": "wan2.1_i2v_480p_14B_fp16.safetensors",
        "weight_dtype": "default"
      },
      "class_type": "UNETLoader",
      "_meta": {
        "title": "Load Diffusion Model"
      }
    },
    "38": {
      "inputs": {
        "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
        "type": "wan",
        "device": "default"
      },
      "class_type": "CLIPLoader",
      "_meta": {
        "title": "Load CLIP"
      }
    },
    "39": {
      "inputs": {
        "vae_name": "wan_2.1_vae.safetensors"
      },
      "class_type": "VAELoader",
      "_meta": {
        "title": "Load VAE"
      }
    },
    "49": {
      "inputs": {
        "clip_name": "clip_vision_h.safetensors"
      },
      "class_type": "CLIPVisionLoader",
      "_meta": {
        "title": "Load CLIP Vision"
      }
    },
    "50": {
      "inputs": {
        "width": 512,
        "height": 512,
        "length": 33,
        "batch_size": 1,
        "positive": [
          "6",
          0
        ],
        "negative": [
          "7",
          0
        ],
        "vae": [
          "39",
          0
        ],
        "clip_vision_output": [
          "51",
          0
        ],
        "start_image": [
          "52",
          0
        ]
      },
      "class_type": "WanImageToVideo",
      "_meta": {
        "title": "WanImageToVideo"
      }
    },
    "51": {
      "inputs": {
        "crop": "none",
        "clip_vision": [
          "49",
          0
        ],
        "image": [
          "52",
          0
        ]
      },
      "class_type": "CLIPVisionEncode",
      "_meta": {
        "title": "CLIP Vision Encode"
      }
    },
    "52": {
      "inputs": {
        "image": "flux_dev_example.png"
      },
      "class_type": "LoadImage",
      "_meta": {
        "title": "Load Image"
      }
    },
    "54": {
      "inputs": {
        "shift": 8,
        "model": [
          "37",
          0
        ]
      },
      "class_type": "ModelSamplingSD3",
      "_meta": {
        "title": "ModelSamplingSD3"
      }
    },
    "55": {
      "inputs": {
        "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors",
        "save_to": "clip",
        "filename": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
        "token": ""
      },
      "class_type": "AssetDownloader",
      "_meta": {
        "title": "Requires Asset"
      }
    },
    "56": {
      "inputs": {
        "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_480p_14B_fp16.safetensors",
        "save_to": "diffusion_models",
        "filename": "wan2.1_i2v_480p_14B_fp16.safetensors",
        "token": ""
      },
      "class_type": "AssetDownloader",
      "_meta": {
        "title": "Requires Asset"
      }
    },
    "57": {
      "inputs": {
        "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors",
        "save_to": "clip_vision",
        "filename": "clip_vision_h.safetensors",
        "token": ""
      },
      "class_type": "AssetDownloader",
      "_meta": {
        "title": "Requires Asset"
      }
    },
    "58": {
      "inputs": {
        "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors",
        "save_to": "vae",
        "filename": "wan_2.1_vae.safetensors",
        "token": ""
      },
      "class_type": "AssetDownloader",
      "_meta": {
        "title": "Requires Asset"
      }
    }
  },
  "extra_data": {
    "extra_pnginfo": {
      "workflow": {
        "id": "5408edec-ec0f-4cc6-904f-2dd4ae4034d2",
        "revision": 0,
        "last_node_id": 58,
        "last_link_id": 111,
        "nodes": [
          {
            "id": 8,
            "type": "VAEDecode",
            "pos": [
              1210,
              190
            ],
            "size": [
              210,
              46
            ],
            "flags": {},
            "order": 15,
            "mode": 0,
            "inputs": [
              {
                "name": "samples",
                "type": "LATENT",
                "link": 35
              },
              {
                "name": "vae",
                "type": "VAE",
                "link": 76
              }
            ],
            "outputs": [
              {
                "name": "IMAGE",
                "type": "IMAGE",
                "slot_index": 0,
                "links": [
                  56,
                  93
                ]
              }
            ],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "VAEDecode"
            },
            "widgets_values": []
          },
          {
            "id": 39,
            "type": "VAELoader",
            "pos": [
              866.3932495117188,
              499.18597412109375
            ],
            "size": [
              306.36004638671875,
              58
            ],
            "flags": {},
            "order": 0,
            "mode": 0,
            "inputs": [],
            "outputs": [
              {
                "name": "VAE",
                "type": "VAE",
                "slot_index": 0,
                "links": [
                  76,
                  99
                ]
              }
            ],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "VAELoader"
            },
            "widgets_values": [
              "wan_2.1_vae.safetensors"
            ]
          },
          {
            "id": 28,
            "type": "SaveAnimatedWEBP",
            "pos": [
              1460,
              190
            ],
            "size": [
              870.8511352539062,
              643.7430419921875
            ],
            "flags": {},
            "order": 16,
            "mode": 0,
            "inputs": [
              {
                "name": "images",
                "type": "IMAGE",
                "link": 56
              }
            ],
            "outputs": [],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30"
            },
            "widgets_values": [
              "ComfyUI",
              16,
              false,
              90,
              "default"
            ]
          },
          {
            "id": 47,
            "type": "SaveWEBM",
            "pos": [
              2367.213134765625,
              193.6114959716797
            ],
            "size": [
              315,
              130
            ],
            "flags": {},
            "order": 17,
            "mode": 4,
            "inputs": [
              {
                "name": "images",
                "type": "IMAGE",
                "link": 93
              }
            ],
            "outputs": [],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "SaveWEBM"
            },
            "widgets_values": [
              "ComfyUI",
              "vp9",
              24,
              32
            ]
          },
          {
            "id": 7,
            "type": "CLIPTextEncode",
            "pos": [
              413,
              389
            ],
            "size": [
              425.27801513671875,
              180.6060791015625
            ],
            "flags": {},
            "order": 12,
            "mode": 0,
            "inputs": [
              {
                "name": "clip",
                "type": "CLIP",
                "link": 75
              }
            ],
            "outputs": [
              {
                "name": "CONDITIONING",
                "type": "CONDITIONING",
                "slot_index": 0,
                "links": [
                  98
                ]
              }
            ],
            "title": "CLIP Text Encode (Negative Prompt)",
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "CLIPTextEncode"
            },
            "widgets_values": [
              "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走"
            ],
            "color": "#322",
            "bgcolor": "#533"
          },
          {
            "id": 50,
            "type": "WanImageToVideo",
            "pos": [
              673.0507202148438,
              627.272705078125
            ],
            "size": [
              342.5999755859375,
              210
            ],
            "flags": {},
            "order": 13,
            "mode": 0,
            "inputs": [
              {
                "name": "positive",
                "type": "CONDITIONING",
                "link": 97
              },
              {
                "name": "negative",
                "type": "CONDITIONING",
                "link": 98
              },
              {
                "name": "vae",
                "type": "VAE",
                "link": 99
              },
              {
                "name": "clip_vision_output",
                "shape": 7,
                "type": "CLIP_VISION_OUTPUT",
                "link": 107
              },
              {
                "name": "start_image",
                "shape": 7,
                "type": "IMAGE",
                "link": 106
              }
            ],
            "outputs": [
              {
                "name": "positive",
                "type": "CONDITIONING",
                "slot_index": 0,
                "links": [
                  101
                ]
              },
              {
                "name": "negative",
                "type": "CONDITIONING",
                "slot_index": 1,
                "links": [
                  102
                ]
              },
              {
                "name": "latent",
                "type": "LATENT",
                "slot_index": 2,
                "links": [
                  103
                ]
              }
            ],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "WanImageToVideo"
            },
            "widgets_values": [
              512,
              512,
              33,
              1
            ]
          },
          {
            "id": 3,
            "type": "KSampler",
            "pos": [
              863,
              187
            ],
            "size": [
              315,
              262
            ],
            "flags": {},
            "order": 14,
            "mode": 0,
            "inputs": [
              {
                "name": "model",
                "type": "MODEL",
                "link": 111
              },
              {
                "name": "positive",
                "type": "CONDITIONING",
                "link": 101
              },
              {
                "name": "negative",
                "type": "CONDITIONING",
                "link": 102
              },
              {
                "name": "latent_image",
                "type": "LATENT",
                "link": 103
              }
            ],
            "outputs": [
              {
                "name": "LATENT",
                "type": "LATENT",
                "slot_index": 0,
                "links": [
                  35
                ]
              }
            ],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "KSampler"
            },
            "widgets_values": [
              978813273223451,
              "randomize",
              20,
              6,
              "uni_pc",
              "simple",
              1
            ]
          },
          {
            "id": 49,
            "type": "CLIPVisionLoader",
            "pos": [
              40.18779754638672,
              812.57470703125
            ],
            "size": [
              315,
              58
            ],
            "flags": {},
            "order": 1,
            "mode": 0,
            "inputs": [],
            "outputs": [
              {
                "name": "CLIP_VISION",
                "type": "CLIP_VISION",
                "slot_index": 0,
                "links": [
                  94
                ]
              }
            ],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "CLIPVisionLoader"
            },
            "widgets_values": [
              "clip_vision_h.safetensors"
            ]
          },
          {
            "id": 52,
            "type": "LoadImage",
            "pos": [
              40.18779754638672,
              932.5743408203125
            ],
            "size": [
              315,
              314
            ],
            "flags": {},
            "order": 2,
            "mode": 0,
            "inputs": [],
            "outputs": [
              {
                "name": "IMAGE",
                "type": "IMAGE",
                "slot_index": 0,
                "links": [
                  106,
                  109
                ]
              },
              {
                "name": "MASK",
                "type": "MASK",
                "slot_index": 1,
                "links": null
              }
            ],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "LoadImage"
            },
            "widgets_values": [
              "flux_dev_example.png",
              "image"
            ]
          },
          {
            "id": 54,
            "type": "ModelSamplingSD3",
            "pos": [
              510,
              70
            ],
            "size": [
              315,
              58
            ],
            "flags": {},
            "order": 10,
            "mode": 0,
            "inputs": [
              {
                "name": "model",
                "type": "MODEL",
                "link": 110
              }
            ],
            "outputs": [
              {
                "name": "MODEL",
                "type": "MODEL",
                "slot_index": 0,
                "links": [
                  111
                ]
              }
            ],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "ModelSamplingSD3"
            },
            "widgets_values": [
              8
            ]
          },
          {
            "id": 51,
            "type": "CLIPVisionEncode",
            "pos": [
              380.18817138671875,
              812.57470703125
            ],
            "size": [
              253.60000610351562,
              78
            ],
            "flags": {},
            "order": 9,
            "mode": 0,
            "inputs": [
              {
                "name": "clip_vision",
                "type": "CLIP_VISION",
                "link": 94
              },
              {
                "name": "image",
                "type": "IMAGE",
                "link": 109
              }
            ],
            "outputs": [
              {
                "name": "CLIP_VISION_OUTPUT",
                "type": "CLIP_VISION_OUTPUT",
                "slot_index": 0,
                "links": [
                  107
                ]
              }
            ],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "CLIPVisionEncode"
            },
            "widgets_values": [
              "none"
            ]
          },
          {
            "id": 56,
            "type": "RequiresAsset",
            "pos": [
              -243.1000213623047,
              412.86444091796875
            ],
            "size": [
              289.60235595703125,
              130
            ],
            "flags": {},
            "order": 3,
            "mode": 0,
            "inputs": [],
            "outputs": [],
            "properties": {
              "Node name for S&R": "RequiresAsset"
            },
            "widgets_values": [
              "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_480p_14B_fp16.safetensors",
              "diffusion_models",
              "wan2.1_i2v_480p_14B_fp16.safetensors",
              ""
            ]
          },
          {
            "id": 57,
            "type": "RequiresAsset",
            "pos": [
              -243.1000213623047,
              604.3241577148438
            ],
            "size": [
              289.6023254394531,
              130
            ],
            "flags": {},
            "order": 4,
            "mode": 0,
            "inputs": [],
            "outputs": [],
            "properties": {
              "Node name for S&R": "RequiresAsset"
            },
            "widgets_values": [
              "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors",
              "clip_vision",
              "clip_vision_h.safetensors",
              ""
            ]
          },
          {
            "id": 37,
            "type": "UNETLoader",
            "pos": [
              29.76833152770996,
              40.69501495361328
            ],
            "size": [
              346.7470703125,
              82
            ],
            "flags": {},
            "order": 5,
            "mode": 0,
            "inputs": [],
            "outputs": [
              {
                "name": "MODEL",
                "type": "MODEL",
                "slot_index": 0,
                "links": [
                  110
                ]
              }
            ],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "UNETLoader"
            },
            "widgets_values": [
              "wan2.1_i2v_480p_14B_fp16.safetensors",
              "default"
            ]
          },
          {
            "id": 55,
            "type": "RequiresAsset",
            "pos": [
              64.27653503417969,
              412.86444091796875
            ],
            "size": [
              294.1608581542969,
              130
            ],
            "flags": {},
            "order": 6,
            "mode": 0,
            "inputs": [],
            "outputs": [],
            "properties": {
              "Node name for S&R": "RequiresAsset"
            },
            "widgets_values": [
              "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors",
              "clip",
              "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
              ""
            ]
          },
          {
            "id": 38,
            "type": "CLIPLoader",
            "pos": [
              -11.909887313842773,
              191.3024444580078
            ],
            "size": [
              390,
              106
            ],
            "flags": {},
            "order": 7,
            "mode": 0,
            "inputs": [],
            "outputs": [
              {
                "name": "CLIP",
                "type": "CLIP",
                "slot_index": 0,
                "links": [
                  74,
                  75
                ]
              }
            ],
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "CLIPLoader"
            },
            "widgets_values": [
              "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
              "wan",
              "default"
            ]
          },
          {
            "id": 58,
            "type": "RequiresAsset",
            "pos": [
              67.1648941040039,
              603.0263671875
            ],
            "size": [
              289.6023254394531,
              130
            ],
            "flags": {},
            "order": 8,
            "mode": 0,
            "inputs": [],
            "outputs": [],
            "properties": {
              "Node name for S&R": "RequiresAsset"
            },
            "widgets_values": [
              "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors",
              "vae",
              "wan_2.1_vae.safetensors",
              ""
            ]
          },
          {
            "id": 6,
            "type": "CLIPTextEncode",
            "pos": [
              415,
              186
            ],
            "size": [
              422.84503173828125,
              164.31304931640625
            ],
            "flags": {},
            "order": 11,
            "mode": 0,
            "inputs": [
              {
                "name": "clip",
                "type": "CLIP",
                "link": 74
              }
            ],
            "outputs": [
              {
                "name": "CONDITIONING",
                "type": "CONDITIONING",
                "slot_index": 0,
                "links": [
                  97
                ]
              }
            ],
            "title": "CLIP Text Encode (Positive Prompt)",
            "properties": {
              "cnr_id": "comfy-core",
              "ver": "0.3.30",
              "Node name for S&R": "CLIPTextEncode"
            },
            "widgets_values": [
              "a cute anime girl with massive fennec ears and a big fluffy tail wearing a maid outfit turning around"
            ],
            "color": "#232",
            "bgcolor": "#353"
          }
        ],
        "links": [
          [
            35,
            3,
            0,
            8,
            0,
            "LATENT"
          ],
          [
            56,
            8,
            0,
            28,
            0,
            "IMAGE"
          ],
          [
            74,
            38,
            0,
            6,
            0,
            "CLIP"
          ],
          [
            75,
            38,
            0,
            7,
            0,
            "CLIP"
          ],
          [
            76,
            39,
            0,
            8,
            1,
            "VAE"
          ],
          [
            93,
            8,
            0,
            47,
            0,
            "IMAGE"
          ],
          [
            94,
            49,
            0,
            51,
            0,
            "CLIP_VISION"
          ],
          [
            97,
            6,
            0,
            50,
            0,
            "CONDITIONING"
          ],
          [
            98,
            7,
            0,
            50,
            1,
            "CONDITIONING"
          ],
          [
            99,
            39,
            0,
            50,
            2,
            "VAE"
          ],
          [
            101,
            50,
            0,
            3,
            1,
            "CONDITIONING"
          ],
          [
            102,
            50,
            1,
            3,
            2,
            "CONDITIONING"
          ],
          [
            103,
            50,
            2,
            3,
            3,
            "LATENT"
          ],
          [
            106,
            52,
            0,
            50,
            4,
            "IMAGE"
          ],
          [
            107,
            51,
            0,
            50,
            3,
            "CLIP_VISION_OUTPUT"
          ],
          [
            109,
            52,
            0,
            51,
            1,
            "IMAGE"
          ],
          [
            110,
            37,
            0,
            54,
            0,
            "MODEL"
          ],
          [
            111,
            54,
            0,
            3,
            0,
            "MODEL"
          ]
        ],
        "groups": [
          {
            "id": 1,
            "title": "Download Dependencies",
            "bounding": [
              -261.3348083496094,
              325.6006774902344,
              639.4381713867188,
              420.1655578613281
            ],
            "color": "#3f789e",
            "font_size": 24,
            "flags": {}
          }
        ],
        "config": {},
        "extra": {
          "ds": {
            "scale": 1.2284597357367768,
            "offset": [
              -603.4464075037214,
              126.83061746741666
            ]
          },
          "frontendVersion": "1.17.11"
        },
        "version": 0.4
      }
    }
  }
}